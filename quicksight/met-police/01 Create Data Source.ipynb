{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:dodgerblue\">01 Create Data Source</p>\n",
    "*We will upload a datasource file which represents stop and search statistics performed by the London Metropolitan Police*  \n",
    "\n",
    "- this notebook creates the following:\n",
    "  - s3 bucket to:\n",
    "    - drop datasource files into \n",
    "    - used as resource for redshift\n",
    "  - iam\n",
    "    - roles\n",
    "    - policies\n",
    "  - redshift cluster\n",
    "    - model management\n",
    "    - security management\n",
    "  - secrets manager\n",
    "    - cluster and database secret credentials\n",
    "  - includes clean up cells to delete all above  \n",
    "  \n",
    "(At least Kernel 3.11.6 - venv if local)\n",
    "<hr style=\"border:1px dotted; color:floralwhite\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:deeppink\">GETTING STARTED</span>\n",
    "# Requirements for this Lab (macOS)\n",
    "- *See <span style=\"color:gold\">Appendix</span> at the bottom of this lab to install macOS requirements, windows requirements will be similar, apart from Homebrew.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted\">\n",
    "<hr style=\"border:1px dotted;color:greenyellow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:greenyellow\">Set Up Requirements</p>\n",
    "- we do these setup cells here because we can then use the vars and clients to clean up resources later without having to run multiple cells if we lose the kernel  \n",
    "  \n",
    "-  <span style=\"color:greenyellow\">Please note we use us-west-2 region as Q in QuickSight is not available worldwide yet<span>\n",
    "\n",
    "- vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import random\n",
    "\n",
    "# verify AWS account and store in myAccountNumber\n",
    "myAccountNumber = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "print('My account number: {}'.format(myAccountNumber))\n",
    "\n",
    "# region - we use us-west-2 as Q in QuickSight is limited in other reasons\n",
    "myRegion='us-west-2'\n",
    "myLabPrefix='doit-quicksight-london-met-'\n",
    "\n",
    "# bucket - MUST BE A UNIQUE NAME hence the random postfixes\n",
    "myBucket=myLabPrefix + 'bucket-' + str(random.randint(0, 1000)) + '-' + str(random.randint(0, 1000))\n",
    "\n",
    "# iam\n",
    "myRoleRedshiftAttached=myLabPrefix+'redshift-attached-role'\n",
    "myRoleRedshiftAttachedARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "myRoleRedshiftCopy=myLabPrefix+'redshift-copy-role'\n",
    "myPolicyRedshiftCopy1=myLabPrefix + 'redshift-copy-policy'\n",
    "\n",
    "myRoleQuickSight=myLabPrefix + '-service-role'\n",
    "myPolicyQuickSight1=myLabPrefix + '??-policy'\n",
    "myRoleQuickSightARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "# Redshift\n",
    "myDBClusterIdentifier=myLabPrefix + 'cluster'\n",
    "myRedshiftDB=\"london-met\"\n",
    "mySecretRedshiftDevLead=myLabPrefix + 'redshift-devlead-secret'\n",
    "mySecretRedshiftDevLeadARN='RETRIEVED BELOW ONCE CREATED'\n",
    "mySecretRedshiftMasterARN='RETRIEVED BELOW ONCE CREATED'\n",
    "\n",
    "# network\n",
    "myVPC=myLabPrefix + 'redshift-vpc'\n",
    "mySGRedshift=myLabPrefix + 'redshift-sg'\n",
    "mySGQuickSight=myLabPrefix + 'quicksight-sg'\n",
    "mySubnetGroupRedshift=myLabPrefix + 'redshift-subnet-group'\n",
    "\n",
    "# local client path for resources\n",
    "myPathForDataSources='/Users/simondavies/Documents/GitHub/labs/quicksight/met-police/resources/datasource/'\n",
    "\n",
    "# jupypter notebook path for resources if notebook is used in AWS for example\n",
    "#myPathForDataSources='/home/ec2-user/SageMaker/labs/quicksight/met-police/resources/datasource/'\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create required clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3\n",
    "s3 = boto3.client('s3', region_name=myRegion)\n",
    "\n",
    "# ec2 (reqd for networking services)\n",
    "ec2 = boto3.client('ec2', region_name=myRegion)\n",
    "\n",
    "# redshift\n",
    "redshift = boto3.client('redshift', region_name=myRegion)\n",
    "redshiftData = boto3.client('redshift-data', region_name=myRegion)\n",
    "\n",
    "# quicksight\n",
    "quicksight = boto3.client('quicksight', region_name=myRegion)\n",
    "\n",
    "# iam\n",
    "iam = boto3.client('iam', region_name=myRegion)\n",
    "\n",
    "# secrets manager\n",
    "secrets = boto3.client('secretsmanager', region_name=myRegion)\n",
    "\n",
    "# logs (cloudwatch)\n",
    "logs = boto3.client('logs', region_name=myRegion)\n",
    "\n",
    "# cidr blocks\n",
    "vpcCIDR = \"10.0.0.0/24\"\n",
    "subnetaCIDR=\"10.0.0.0/25\"\n",
    "subnetbCIDR=\"10.0.0.128/25\"\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tags for all services that are created - you can never have too many tags!\n",
    "  - make sure you have a tagging policy in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tags added to all services we create\n",
    "myTags = [\n",
    "    {\"Key\": \"env\", \"Value\": \"non_prod\"},\n",
    "    {\"Key\": \"owner\", \"Value\": myLabPrefix + \"lab\"},\n",
    "    {\"Key\": \"project\", \"Value\": myLabPrefix + \"bi\"},\n",
    "    {\"Key\": \"author\", \"Value\": \"simon\"},\n",
    "]\n",
    "myTagsDct = {\n",
    "    \"env\": \"non_prod\",\n",
    "    \"owner\": myLabPrefix + \"lab\",\n",
    "    \"project\": myLabPrefix + \"bi\",\n",
    "    \"author\": \"simon\",\n",
    "}\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:greenyellow\">\n",
    "<hr style=\"border:1px dotted;color:orchid\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orchid\">Create IAM</p>\n",
    "- roles and policies for the services to interact with other services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iam role and policies which is attached to the redshift cluster giving it required permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no inline policies required\n",
    "\n",
    "# trust policy for the role\n",
    "roleTrust = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\n",
    "                    \"redshift.amazonaws.com\",\n",
    "                    \"redshift-serverless.amazonaws.com\",\n",
    "                    \"sagemaker.amazonaws.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create role\n",
    "role = iam.create_role(\n",
    "    RoleName=myRoleRedshiftAttached,\n",
    "    AssumeRolePolicyDocument=json.dumps(roleTrust),\n",
    "    Description=\"Service role for Redshift use\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# attach policies to role\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], \n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonRedshiftAllCommandsFullAccess'\n",
    ")\n",
    "\n",
    "myRoleRedshiftAttachedARN = role['Role']['Arn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iam role and policy allowing COPY from S3 to Redshift using the COPY command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline policies\n",
    "policyJson = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}/*\".format(myBucket),\n",
    "                \"arn:aws:s3:::{}\".format(myBucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the policy\n",
    "policy1 = iam.create_policy(\n",
    "    PolicyName=myPolicyRedshiftCopy1,\n",
    "    PolicyDocument=json.dumps(policyJson),\n",
    "    Description=\"Policy allowing Redshift COPY to use s3\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# trust policy for the role\n",
    "roleTrust = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"redshift.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# create role\n",
    "role = iam.create_role(\n",
    "    RoleName=myRoleRedshiftCopy,\n",
    "    AssumeRolePolicyDocument=json.dumps(roleTrust),\n",
    "    Description=\"Service role for Redshift use\",\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# attach policies to role\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role[\"Role\"][\"RoleName\"], \n",
    "    PolicyArn=policy1[\"Policy\"][\"Arn\"]\n",
    ")\n",
    "\n",
    "myRoleRedshiftCopyARN = role['Role']['Arn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:orchid\">\n",
    "<hr style=\"border:1px dotted;color:crimson\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:crimson\">Create S3 Bucket</p>\n",
    "- defaults used, will use sse-s3 encryption and block public access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bucket\n",
    "s3.create_bucket(\n",
    "    Bucket=myBucket, CreateBucketConfiguration={\"LocationConstraint\": myRegion}\n",
    ")\n",
    "s3.put_bucket_tagging(Bucket=myBucket, Tagging={\"TagSet\": myTags})\n",
    "\n",
    "# create a \"folder\" - really keys as S3 is flat\n",
    "s3.put_object(Bucket=myBucket, Key=\"datasource/\")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upload resource files to s3 that will be used to create the knowledge base with\n",
    "  - includes metadata file\n",
    "  - https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-ds.html#kb-ds-metadata\n",
    "  - If you're adding metadata to a vector index in an Amazon Aurora database cluster, you must add a column to the table for each metadata attribute in your metadata files before starting ingestion. The metadata attribute values will be written to these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload each file to the S3 bucket\n",
    "files = [\n",
    "    {\n",
    "        's3key': 'datasource/Stops_LDS_Extract_24Months.csv',\n",
    "        'localpath': '{}Stops_LDS_Extract_24Months.csv'.format(myPathForDataSources)\n",
    "    }\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print ('uploading: {}'.format(file['s3key']))\n",
    "    s3.upload_file(file['localpath'], myBucket, file['s3key'], ExtraArgs={'StorageClass': 'STANDARD'})\n",
    "    print ('uploaded: {}'.format(file['s3key']))\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:crimson\">\n",
    "<hr style=\"border:1px dotted;color:ForestGreen\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:ForestGreen\">Create Network</p>\n",
    "- vpc  \n",
    "  - /24 is a reasonable size for a small VPC. This gives you 256 IPs, but note the following:\n",
    "  - The first 3 and last in the IP range is reserved by AWS\n",
    "  - VPC cidr blocks cannot overlap\n",
    "  - Each subnet in a vpc must have a netmask block between /28 (16 IPs) and /16 (65536 IPs)\n",
    "  - RDS typically requires at least 2 subnets if a standby or read replica is provisioned\n",
    "\n",
    "https://docs.aws.amazon.com/vpc/latest/userguide/vpc-cidr-blocks.html  \n",
    "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_VPC.Scenarios.html  \n",
    "https://mxtoolbox.com/subnetcalculator.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift vpc\n",
    "vpc_redshift = ec2.create_vpc(\n",
    "    CidrBlock=vpcCIDR,\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"vpc\",\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 private subnets\n",
    "  - We'll break the /24 of the VPC over 2 subnets of /25 each\n",
    "  - The first 4 and last in the IP range is reserved by AWS\n",
    "  - Subnet cidr blocks cannot overlap\n",
    "  - RDS typically requires 3 subnets\n",
    "\n",
    "https://docs.aws.amazon.com/vpc/latest/userguide/subnet-sizing.html\n",
    "https://mxtoolbox.com/subnetcalculator.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vpc-redshift subnets\n",
    "subnet_a_redshift = ec2.create_subnet(\n",
    "    CidrBlock=subnetaCIDR,\n",
    "    AvailabilityZone=myRegion + \"a\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"subnet\",\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC + \"-subnet-a\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "subnet_b_redshift = ec2.create_subnet(\n",
    "    CidrBlock=subnetbCIDR,\n",
    "    AvailabilityZone=myRegion + \"b\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"subnet\",\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": myVPC + \"-subnet-b\"},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# create subnet group\n",
    "subnet_group_redshift = redshift.create_cluster_subnet_group(\n",
    "    Description=\"Redshift subnet group\",\n",
    "    ClusterSubnetGroupName=mySubnetGroupRedshift,\n",
    "    SubnetIds=[\n",
    "        subnet_a_redshift[\"Subnet\"][\"SubnetId\"],\n",
    "        subnet_b_redshift[\"Subnet\"][\"SubnetId\"],\n",
    "    ],\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": mySubnetGroupRedshift},\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- redshift security group\n",
    "  - we need to create this now as we can reference its arn in the inbound and outbound rules of the quicksight sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create redshift security group\n",
    "sg_redshift = ec2.create_security_group(\n",
    "    GroupName=mySGRedshift,\n",
    "    Description=\"sg for redshift\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"security-group\",\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": mySGRedshift},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quicksight security group\n",
    "  - we need to create this now as we can reference its arn in the inbound and outbound rules of the redshift sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create quicksight security group\n",
    "sg_quicksight = ec2.create_security_group(\n",
    "    GroupName=mySGQuickSight,\n",
    "    Description=\"sg for quicksight\",\n",
    "    VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"],\n",
    "    TagSpecifications=[\n",
    "        {\n",
    "            \"ResourceType\": \"security-group\",\n",
    "            \"Tags\": [\n",
    "                *myTags,\n",
    "                {\"Key\": \"Name\", \"Value\": mySGQuickSight},\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rules for redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inbound rule allowing quicksight to reach redshift\n",
    "ec2.authorize_security_group_ingress(\n",
    "    GroupId=sg_redshift[\"GroupId\"],\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            \"FromPort\": 5439,\n",
    "            \"ToPort\": 5439,\n",
    "            \"IpProtocol\": \"tcp\",\n",
    "            'UserIdGroupPairs': [\n",
    "                {\n",
    "                    'Description': 'allow quicksight to reach redshift',\n",
    "                    'GroupId': sg_quicksight[\"GroupId\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# create outbound rule allowing redshift to reach quicksight\n",
    "ec2.authorize_security_group_egress(\n",
    "    GroupId=sg_redshift[\"GroupId\"],\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            \"FromPort\": 5439,\n",
    "            \"ToPort\": 5439,\n",
    "            \"IpProtocol\": \"tcp\",\n",
    "            'UserIdGroupPairs': [\n",
    "                {\n",
    "                    'Description': 'allow redshift to reach quicksight',\n",
    "                    'GroupId': sg_quicksight[\"GroupId\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rules for quicksight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inbound rule allowing redshift to return quicksight\n",
    "ec2.authorize_security_group_ingress(\n",
    "    GroupId=sg_quicksight[\"GroupId\"],\n",
    "    IpPermissions=[\n",
    "        {\n",
    "            \"FromPort\": 5439,\n",
    "            \"ToPort\": 5439,\n",
    "            \"IpProtocol\": \"tcp\",\n",
    "            'UserIdGroupPairs': [\n",
    "                {\n",
    "                    'Description': 'allow redshift to return to quicksight',\n",
    "                    'GroupId': sg_redshift[\"GroupId\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:ForestGreen\">\n",
    "<hr style=\"border:1px dotted;color:lightskyblue\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:LightSkyBlue\">Create Redshift Cluster</p>\n",
    "- redshift cluster\n",
    "  - we create a private master node with 2 data nodes\n",
    "  - we use a single az (multi az does not support dc2)\n",
    "  - best practice is multi az with a master node and a number of compute nodes  \n",
    "  \n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a dc2.large here as we have very small, static datasets\n",
    "# if you have larger datasets, or expect regular growth, you can change the instance type to something more suitable\n",
    "# eg ra3 which separates storage and compute for better scaling - especially useful with regular growth\n",
    "redshift_cluster = redshift.create_cluster(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    DBName=myRedshiftDB,\n",
    "    NodeType='dc2.large',\n",
    "    MasterUsername='masteruser',\n",
    "    ManageMasterPassword=True,\n",
    "    ClusterSubnetGroupName=subnet_group_redshift[\"ClusterSubnetGroup\"][\"ClusterSubnetGroupName\"],\n",
    "    VpcSecurityGroupIds=[sg_redshift[\"GroupId\"]],\n",
    "    ClusterType='multi-node',\n",
    "    NumberOfNodes=2,\n",
    "    PubliclyAccessible=False,\n",
    "    Encrypted=True,\n",
    "    IamRoles=[myRoleRedshiftAttachedARN],\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": \"{}\".format(myDBClusterIdentifier)},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# grab the secrets manager secret arn\n",
    "mySecretRedshiftMasterARN=redshift_cluster['Cluster']['MasterPasswordSecretArn']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the cluster to finish creating\n",
    "  - cant create an instance until the cluster is ready\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is available and available</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 2 mins to create the cluster\n",
    "cluster=redshift.describe_clusters(ClusterIdentifier=myDBClusterIdentifier)['Clusters'][0]\n",
    "print('ClusterStatus={}\\nClusterAvailabilityStatus (for queries)={}'.format(cluster['ClusterStatus'],cluster['ClusterAvailabilityStatus']))\n",
    "print('MasterPasswordSecretArn={}'.format(cluster['MasterPasswordSecretArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the Secrets Manager masteruser secret ARN, we need these credentials if you want to login to the AWS redshift Query Editor\n",
    "print('mySecretRedshiftMasterARN={}'.format(mySecretRedshiftMasterARN))\n",
    "print('myRedshiftDB={}'.format(myRedshiftDB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate another iam role with the cluster which will allow it to COPY from s3\n",
    "response = redshift.modify_cluster_iam_roles(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    AddIamRoles=[myRoleRedshiftCopyARN]\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:lightskyblue\">\n",
    "<hr style=\"border:1px dotted;color:Coral\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:Coral\">Create A Very Simple Redshift Security Model</p>\n",
    "- user\n",
    "  - we create a superuser that has full access - suitable for owners or administrators\n",
    "  - we create a secret to use when authorising api execute statements\n",
    "  - best practice we would create users for specific roles in groups or assigned roles with grants\n",
    "  \n",
    "https://docs.aws.amazon.com/redshift/latest/mgmt/redshift-secrets-manager-integration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a secret for a dev lead user\n",
    "# we randomise a password to use\n",
    "usernameDevLead = 'dev_lead'\n",
    "passwordDevLead = secrets.get_random_password(\n",
    "    PasswordLength=16,\n",
    "    ExcludeNumbers=False,\n",
    "    ExcludePunctuation=True,\n",
    "    ExcludeUppercase=False,\n",
    "    ExcludeLowercase=False,\n",
    "    IncludeSpace=False,\n",
    "    RequireEachIncludedType=True\n",
    ")\n",
    "\n",
    "secretString = {\n",
    "                \"engine\": \"redshift\", \\\n",
    "                \"dbClusterIdentifier\" : myDBClusterIdentifier, \\\n",
    "                'host': cluster['Endpoint']['Address'],\n",
    "                \"username\": usernameDevLead, \\\n",
    "                \"password\": passwordDevLead['RandomPassword'], \\\n",
    "                \"dbname\": myRedshiftDB, \\\n",
    "                \"port\": 5439 \\\n",
    "                }\n",
    "\n",
    "response = secrets.create_secret(\n",
    "    Name=mySecretRedshiftDevLead,\n",
    "    Description=\"stores the credential for the dev lead user who has access to the db created in redshift cluster {}\".format(myDBClusterIdentifier),\n",
    "    SecretString=json.dumps(secretString),\n",
    "    Tags=[\n",
    "        *myTags,\n",
    "        {\"Key\": \"Name\", \"Value\": mySecretRedshiftDevLead},\n",
    "        {\"Key\": \"Redshift\", \"Value\": \"Used by query editor v2 to find this secret when listing secrets to use\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "mySecretRedshiftDevLeadARN = response['ARN']\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the database user - we must use the redshift master user to create the first user in a security model\n",
    "# SQL command to create a database user\n",
    "# https://docs.aws.amazon.com/redshift/latest/dg/r_CREATE_USER.html\n",
    "# create a super user = CREATEUSER\n",
    "sql = f\"\"\"\n",
    "CREATE USER {usernameDevLead}\n",
    "PASSWORD '{passwordDevLead['RandomPassword']}'\n",
    "CREATEUSER;\n",
    "\"\"\"\n",
    "\n",
    "# we connect using the secret for the dev lead database user we created previously\n",
    "execResponse = redshiftData.execute_statement(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    Database=myRedshiftDB,\n",
    "    SecretArn=mySecretRedshiftMasterARN,\n",
    "    Sql=sql,\n",
    "    StatementName='CREATE DEV LEAD SUPER USER'\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the statement has finished</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statementResponse=redshiftData.describe_statement(Id=execResponse['Id'])\n",
    "print('Statement Status={}'.format(statementResponse['Status']))\n",
    "if statementResponse['Status']=='FAILED':\n",
    "    print('Statement Error={}'.format(statementResponse['Error']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:Coral\">\n",
    "<hr style=\"border:1px dotted;color:Aquamarine\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:Aquamarine\">Redshift Data</p>\n",
    "- redshift data\n",
    "  - we can use the redshift data api to execute ddl and dml statements in redshift\n",
    "  - alternatively you could use the redshift query editor v2 via the redshift aws console (or local client, eg dbeaver)\n",
    "  \n",
    "https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create schema\n",
    "redshiftSchema = 'met_police'\n",
    "\n",
    "sql = f\"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS {redshiftSchema}\n",
    "AUTHORIZATION {usernameDevLead};\n",
    "\"\"\"\n",
    "\n",
    "# we connect using the secret for the dev lead database user we created previously\n",
    "execResponse = redshiftData.execute_statement(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    Database=myRedshiftDB,\n",
    "    SecretArn=mySecretRedshiftDevLeadARN,\n",
    "    Sql=sql,\n",
    "    StatementName='CREATE SCHEMA'\n",
    ")\n",
    "\n",
    "print('sql={}'.format(sql))\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the statement has finished</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statementResponse=redshiftData.describe_statement(Id=execResponse['Id'])\n",
    "print('Statement Status={}'.format(statementResponse['Status']))\n",
    "if statementResponse['Status']=='FAILED':\n",
    "    print('Statement Error={}'.format(statementResponse['Error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table - ENCODE AUTO is on by default\n",
    "redshiftTable = 'stop_and_search'\n",
    "\n",
    "sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {redshiftSchema}.{redshiftTable} (\n",
    "    Date DATE,\n",
    "    MPS_Area VARCHAR(255),\n",
    "    Borough_of_Stop VARCHAR(255),\n",
    "    Borough_Code VARCHAR(10),\n",
    "    Officer_OCU VARCHAR(255),\n",
    "    Search_Type VARCHAR(255),\n",
    "    Subject VARCHAR(255),\n",
    "    Reason_for_Stop VARCHAR(255),\n",
    "    Outcome VARCHAR(255),\n",
    "    Outcome_Reason VARCHAR(255),\n",
    "    Age DECIMAL(5,2),\n",
    "    Gender VARCHAR(50),\n",
    "    Ethnic_Appearance VARCHAR(255),\n",
    "    Ethnic_Appearance_Group VARCHAR(50),\n",
    "    Self_defined_Ethnicity VARCHAR(255),\n",
    "    Self_defined_Ethnicity_Group VARCHAR(50),\n",
    "    Stop_Count INT,\n",
    "    Source VARCHAR(50)\n",
    ")\n",
    "DISTSTYLE AUTO\n",
    "SORTKEY AUTO;\n",
    "\"\"\"\n",
    "\n",
    "# we connect using the secret for the dev lead database user we created previously\n",
    "execResponse = redshiftData.execute_statement(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    Database=myRedshiftDB,\n",
    "    SecretArn=mySecretRedshiftDevLeadARN,\n",
    "    Sql=sql,\n",
    "    StatementName='CREATE TABLE'\n",
    ")\n",
    "\n",
    "print('sql={}'.format(sql))\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the statement has finished</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statementResponse=redshiftData.describe_statement(Id=execResponse['Id'])\n",
    "print('Statement Status={}'.format(statementResponse['Status']))\n",
    "if statementResponse['Status']=='FAILED':\n",
    "    print('Statement Error={}'.format(statementResponse['Error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRoleRedshiftCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY data from S3 into redshift\n",
    "\n",
    "# S3 bucket and file details\n",
    "s3File = 'datasource/Stops_LDS_Extract_24Months.csv'\n",
    "\n",
    "# SQL command to copy data from S3 to Redshift\n",
    "# https://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-source-s3.html\n",
    "sql = f\"\"\"\n",
    "COPY {redshiftSchema}.{redshiftTable}\n",
    "FROM 's3://{myBucket}/{s3File}'\n",
    "IAM_ROLE '{myRoleRedshiftCopyARN}'\n",
    "REGION '{myRegion}'\n",
    "CSV\n",
    "IGNOREHEADER 1\n",
    "DELIMITER ','\n",
    "ACCEPTINVCHARS;\n",
    "\"\"\"\n",
    "\n",
    "# we connect using the secret for the dev lead database user we created previously\n",
    "execResponse = redshiftData.execute_statement(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    Database=myRedshiftDB,\n",
    "    SecretArn=mySecretRedshiftDevLeadARN,\n",
    "    Sql=sql,\n",
    "    StatementName='COPY FROM S3'\n",
    ")\n",
    "\n",
    "print('sql={}'.format(sql))\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the statement has finished</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statementResponse=redshiftData.describe_statement(Id=execResponse['Id'])\n",
    "print('Statement Status={}'.format(statementResponse['Status']))\n",
    "if statementResponse['Status']=='FAILED':\n",
    "    print('Statement Error={}'.format(statementResponse['Error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the row count\n",
    "sql = f\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM {redshiftSchema}.{redshiftTable};\n",
    "\"\"\"\n",
    "\n",
    "# we connect using the secret for the dev lead database user we created previously\n",
    "execResponse = redshiftData.execute_statement(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    Database=myRedshiftDB,\n",
    "    SecretArn=mySecretRedshiftDevLeadARN,\n",
    "    Sql=sql,\n",
    "    StatementName='SELECT COUNT'\n",
    ")\n",
    "\n",
    "print('sql={}'.format(sql))\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statementResponse=redshiftData.describe_statement(Id=execResponse['Id'])\n",
    "print('Statement Status={}'.format(statementResponse['Status']))\n",
    "if statementResponse['Status']=='FINISHED':\n",
    "    resultDataSet = redshiftData.get_statement_result(\n",
    "        Id=execResponse['Id']\n",
    "    )\n",
    "    print ('resultDataSet={}'.format(resultDataSet['Records']))\n",
    "if statementResponse['Status']=='FAILED':\n",
    "    print('Statement Error={}'.format(statementResponse['Error']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:Aquamarine\">\n",
    "<hr style=\"border:1px dotted;color:deeppink\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:deeppink\">STACK 01 COMPLETE!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:deeppink\">\n",
    "<hr style=\"border:1px dotted;color:orangered\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:orangered\">Clean Up - DO NOT DO THIS IN THIS LAB!!!!!</p>\n",
    "# <p style=\"color:orangered\">DO NOT RUN THESE UNLESS YOU WANT TO DESTROY EVERYTHING</p>\n",
    "- If you have lost the Kernel, run the cells contained in the <span style=\"color:greenyellow\">Set Up Requirements<span> section before the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete redshift cluster\n",
    "redshift.delete_cluster(\n",
    "    ClusterIdentifier=myDBClusterIdentifier,\n",
    "    SkipFinalClusterSnapshot=True\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wait for the instance to finish deleting\n",
    "  - cant delete dependencies until finished\n",
    "#### <span style=\"color:deeppink\">you can run the following cell multiple times until the status is Deleted</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can take approx 2 mins to create the cluster\n",
    "try:\n",
    "    cluster=redshift.describe_clusters(ClusterIdentifier=myDBClusterIdentifier)\n",
    "    print('ClusterStatus={}'.format(cluster['Clusters'][0]['ClusterStatus']))\n",
    "except:\n",
    "    print(\"Deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete secrets manager\n",
    "# warning, if you use ForceDeleteWithoutRecovery in your own projects there is NO recovery\n",
    "# normally recovery of the secret is available for 7 to 30 days\n",
    "secrets.delete_secret(\n",
    "    SecretId=mySecretRedshiftDevLead, \n",
    "    ForceDeleteWithoutRecovery=True\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete roles and policies\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshiftAttached, PolicyArn='arn:aws:iam::aws:policy/AmazonRedshiftAllCommandsFullAccess'\n",
    ")\n",
    "iam.detach_role_policy(\n",
    "    RoleName=myRoleRedshiftCopy, PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshiftCopy1)\n",
    ")\n",
    "\n",
    "iam.delete_role(RoleName=myRoleRedshiftAttached)\n",
    "iam.delete_role(RoleName=myRoleRedshiftCopy)\n",
    "iam.delete_policy(PolicyArn='arn:aws:iam::{}:policy/{}'.format(myAccountNumber, myPolicyRedshiftCopy1))\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redshift subnet group\n",
    "response = redshift.delete_cluster_subnet_group(\n",
    "    ClusterSubnetGroupName=subnet_group_redshift[\"ClusterSubnetGroup\"][\"ClusterSubnetGroupName\"]\n",
    ")\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subnets\n",
    "response = ec2.delete_subnet(SubnetId=subnet_a_redshift[\"Subnet\"][\"SubnetId\"], DryRun=False)\n",
    "response = ec2.delete_subnet(SubnetId=subnet_b_redshift[\"Subnet\"][\"SubnetId\"], DryRun=False)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ec2.describe_security_group_rules(\n",
    "    Filters=[\n",
    "        {\n",
    "            'Name': 'group-id',\n",
    "            'Values': ['{}'.format(sg_redshift[\"GroupId\"])]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# security group rules - cant delete security groups because they have a dependency on each other in the rules\n",
    "# redshift\n",
    "rules = ec2.describe_security_group_rules(\n",
    "    Filters=[\n",
    "        {\n",
    "            'Name': 'group-id',\n",
    "            'Values': ['{}'.format(sg_redshift[\"GroupId\"])]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "for sgrule in rules['SecurityGroupRules']:\n",
    "    if sgrule['IsEgress']==True:\n",
    "        response = ec2.revoke_security_group_egress(\n",
    "            GroupId=sg_redshift[\"GroupId\"], \n",
    "            SecurityGroupRuleIds=[\n",
    "                sgrule['SecurityGroupRuleId']\n",
    "            ],\n",
    "            DryRun=False\n",
    "        )\n",
    "    else:\n",
    "        response = ec2.revoke_security_group_ingress(\n",
    "            GroupId=sg_redshift[\"GroupId\"], \n",
    "            SecurityGroupRuleIds=[\n",
    "                sgrule['SecurityGroupRuleId']\n",
    "            ],\n",
    "            DryRun=False\n",
    "        )\n",
    "\n",
    "# quicksight\n",
    "rules = ec2.describe_security_group_rules(\n",
    "    Filters=[\n",
    "        {\n",
    "            'Name': 'group-id',\n",
    "            'Values': ['{}'.format(sg_quicksight[\"GroupId\"])]\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "for sgrule in rules['SecurityGroupRules']:\n",
    "    if sgrule['IsEgress']==True:\n",
    "        response = ec2.revoke_security_group_egress(\n",
    "            GroupId=sg_quicksight[\"GroupId\"], \n",
    "            SecurityGroupRuleIds=[\n",
    "                sgrule['SecurityGroupRuleId']\n",
    "            ],\n",
    "            DryRun=False\n",
    "        )\n",
    "    else:\n",
    "        response = ec2.revoke_security_group_ingress(\n",
    "            GroupId=sg_quicksight[\"GroupId\"], \n",
    "            SecurityGroupRuleIds=[\n",
    "                sgrule['SecurityGroupRuleId']\n",
    "            ],\n",
    "            DryRun=False\n",
    "        )\n",
    "\n",
    "\n",
    "# security groups\n",
    "response = ec2.delete_security_group(GroupId=sg_redshift[\"GroupId\"], DryRun=False)\n",
    "response = ec2.delete_security_group(GroupId=sg_quicksight[\"GroupId\"], DryRun=False)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vpc\n",
    "response = ec2.delete_vpc(VpcId=vpc_redshift[\"Vpc\"][\"VpcId\"], DryRun=False)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete s3 bucket\n",
    "# NOTE WARNING - this will delete all objects in the bucket with NO prompt or confirmation\n",
    "s3r = boto3.resource('s3')\n",
    "bucket = s3r.Bucket(myBucket)\n",
    "bucket.objects.all().delete()\n",
    "\n",
    "# delete the bucket\n",
    "response = s3.delete_bucket(Bucket=myBucket)\n",
    "\n",
    "print ('Done! Move to the next cell ->')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:coral\">\n",
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color:gold\">Appendix - Jupyter Install Requirements (macOS)</p>\n",
    "#### <p style=\"color:deeppink\">- If you are running VSCode on a laptop, follow all steps below, including the following:</p>\n",
    "  - Credentials to the AWS account this notebook executes in is provided by AWS configure\n",
    "  - You must already have an IAM user with code (Command Line Interface) access and AWS access keys to be able to use these credentials in AWS configure  \n",
    "    \n",
    "  - arn:aws:iam::###########:user/simon-davies-cli created for this lab  \n",
    "\n",
    "#### <p style=\"color:deeppink\">- If you are running Jupyter inside an AWS Account, you don't need to do anything!</p>\n",
    "\n",
    "### <p style=\"color:gold\">1. Homebrew</p> \n",
    "If you haven't installed Homebrew, you can install it by running the following command here or in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.1 Virtual Environments</p> \n",
    "- You can create a virtual environment that ensures any libraries you install are restricted to the venv.\n",
    "  - https://code.visualstudio.com/docs/python/environments\n",
    "- To enable the virtual environment once you have created it, ensure you open the folder in vs code containing the notebook files, rather than individual notebook files.\n",
    "\n",
    "1. Open folder containing the notebooks (DO NOT OPEN INDIVIDUAL FILES, OPEN THE FOLDER)\n",
    "2. View -> Command Palette\n",
    "3. \\>Python: Create Environment\n",
    "4. Venv Create a '.venv' virtual environment in current workspace\n",
    "5. Select latest (or appropriate Python, eg 3.12.2 64-bit)\n",
    "6. Make sure its selected in the Select Kernel drop down\n",
    "7. If prompted when running the 1st cell, install ipkyKernel\n",
    "8. Install boto3 as provided in a cell below if required\n",
    "9. Ignore cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">1.2 Python</p> \n",
    "Once Homebrew is installed, you can install Python using the following command  \n",
    "*check what you have before installing/upgrading*  \n",
    "*you will need to quit and restart vsCode to use python once installed (or updated)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 --version\n",
    "which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "brew install python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">2. boto3 and other Python requirements</p> \n",
    "* boto3 must be installed on your client\n",
    "  * *Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2.*\n",
    "  * https://boto3.amazonaws.com/v1/documentation/api/latest/index.html  \n",
    "  \n",
    "*check what you have before installing/upgrading*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python3 -m pip show boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:gold\">3. aws configure</p> \n",
    "*Configure aws configure with credentials, and a user that has all of the Bedrock IAM policies required*  \n",
    "https://docs.aws.amazon.com/bedrock/latest/userguide/security_iam_id-based-policy-examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px dotted;color:gold\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
